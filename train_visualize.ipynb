{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Jupyter Notebook ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most of the evaluation of model preformance will require human juding, It's better to experiment in Jupyter Notebook for now.\n",
    "\n",
    "Of course metrics will be put into account, but I noticed with the inital experiment that the model generates white pixels \"Background was white\" everywhere so it decreases the loss. basically the model learnt to generate the background not the required task. it found it easier that way to decrease the loss :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 17:19:26.068499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 17:19:26.903891: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 17:19:28.637127: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory\n",
      "2022-09-29 17:19:28.639732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory\n",
      "2022-09-29 17:19:28.639762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from Utils.model_builder.tf_models import model_01\n",
    "import mlflow\n",
    "from Utils.mlflow.mlflow import mlflow_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.config import load_config_file\n",
    "config_file = load_config_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_uri = config_file[\"mlflow\"][\"track_uri\"]\n",
    "data_version = config_file[\"data_versions\"][-1] # -1 to get the latest only without having to hardcode it in here,\n",
    "                                                # \"Assuming that the last will always will be the updated one\"\n",
    "epochs = config_file[\"train_config\"][\"epochs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "callbacks = []\n",
    "callbacks.append(EarlyStopping(monitor='val_loss',patience=config_file[\"train_config\"][\"earl_stop\"],\n",
    "                verbose=1,restore_best_weights=True))\n",
    "callbacks.append(ReduceLROnPlateau(monitor='val_loss',\n",
    "                patience=config_file[\"train_config\"][\"lr_reduce_pati\"],verbose=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(track_uri)\n",
    "mlflow.set_experiment(\"X_X_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@mlflow_track\n",
    "def exp_x_x_images(dataset,data_version=data_version):\n",
    "    \"\"\"I would like to try generating the same images so that the model can learn the feature of our dataset,\n",
    "    then leverage this learning with our task\"\"\"\n",
    "    mlflow.tensorflow.autolog()\n",
    "    mlflow.log_param(\"Data Version\", data_version)\n",
    "    lr = 0.0001\n",
    "    loss = config_file[\"train_config\"][\"loss\"]\n",
    "    metric = config_file[\"train_config\"][\"metric\"]\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    model = model_01.model(loss_func=loss, optimizer=optimizer, metrics=metric).get_model()\n",
    "    mlflow.log_param(\"Model Module\", \"model_01\")\n",
    "    history = model.fit(dataset,epochs=epochs,callbacks=callbacks)\n",
    "    mse = model.evalute()\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO seek hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"X_Y_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('Combiner-GANS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65a94652bbd286b0d828773e474cbc38e3a40d7d79e2c8d36958604ef8113e79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
